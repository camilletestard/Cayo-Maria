labs(fill = "Hurricane Status",x="Hurricane Status",y="Density of social network")}
#ylim(0,0.4)
# print(density)
# readline(prompt = "pause ")
#hist(data.0$gini); hist(data.1$gini)
{equity <- ggplot(data, aes(x= as.factor(isPost), y=gini, fill=as.factor(isPost) ))+
geom_boxplot()+
geom_jitter(position = position_jitter(0.2), alpha = 0.5)+
ggtitle(paste("Equity of social network pre- vs. post- hurricane ",groupyear[gy],sep=""))+
labs(fill = "Hurricane Status",x="Hurricane Status",y="Gini coeff relative to baseline")}
#ylim(0,0.9)
# print(equity)
# readline(prompt = "pause ")
}
library(ggplot2)
load("C:/Users/Camille Testard/Documents/GitHub/Cayo-Maria/Social_Network_Analysis/AllStats4.RData")
##########################################################
#Sex partner preference
##########################################################
groupyear = c("V.2015","V.2016","V.2017","KK.2015","KK.2017")
for (gy in 1:length(groupyear)){ #For each group
name.0 = paste(groupyear[gy],".0",sep="")
data.0 = AllStats[[name.0]]; data.0$isPost = 0
name.1 = paste(groupyear[gy],".1",sep="")
data.1 = AllStats[[name.1]]; data.1$isPost = 1
data= rbind(data.0, data.1)
pdf(file= paste("SexPartnerPref",groupyear[gy],"pdf",sep = "."), width=5, height=5, onefile = T)
{FFpair <- ggplot(data, aes(x= as.factor(isPost), y=eo.FF, fill=as.factor(isPost) ))+
geom_boxplot()+
geom_jitter(position = position_jitter(0.2), alpha = 0.5)+
ggtitle(paste("FF Pair preference pre- vs. post- hurricane ",groupyear[gy],sep=""))+
labs(fill = "Hurricane Status",x="Hurricane Status",y="Obs./Exp. FF")}
#ylim(0,0.4)
# print(FFpair)
# readline(prompt = "pause ")
{MMpair <- ggplot(data, aes(x= as.factor(isPost), y=eo.MM, fill=as.factor(isPost) ))+
geom_boxplot()+
geom_jitter(position = position_jitter(0.2), alpha = 0.5)+
ggtitle(paste("MM Pair preference pre- vs. post- hurricane ",groupyear[gy],sep=""))+
labs(fill = "Hurricane Status",x="Hurricane Status",y="Obs./Exp. MM")}
#ylim(0,0.4)
# print(MMpair)
# readline(prompt = "pause ")
{crosspair <- ggplot(data, aes(x= as.factor(isPost), y=eo.cross, fill=as.factor(isPost) ))+
geom_boxplot()+
geom_jitter(position = position_jitter(0.2), alpha = 0.5)+
ggtitle(paste("Cross Pair preference pre- vs. post- hurricane ",groupyear[gy],sep=""))+
labs(fill = "Hurricane Status",x="Hurricane Status",y="Obs./Exp. Cross")}
#ylim(0,0.4)
# print(crosspair)
# readline(prompt = "pause ")
}
##########################################################
#Kinship preference
##########################################################
for (gy in 1:length(groupyear)){ #For each group
name.0 = paste(groupyear[gy],".0",sep="")
data.0 = AllStats[[name.0]]; data.0$isPost = 0
name.1 = paste(groupyear[gy],".1",sep="")
data.1 = AllStats[[name.1]]; data.1$isPost = 1
data= rbind(data.0, data.1)
pdf(file= paste("KinshipPartnerPref",groupyear[gy],"pdf",sep = "."), width=5, height=5, onefile = T)
CKpair <- ggplot(data, aes(x= as.factor(isPost), y=eo.ck, fill=as.factor(isPost) ))+
geom_boxplot()+
geom_jitter(position = position_jitter(0.2), alpha = 0.5)+
ggtitle(paste("Close Kin Pair preference pre- vs. post- hurricane ",groupyear[gy],sep=""))+
labs(fill = "Hurricane Status",x="Hurricane Status",y="Obs./Exp. Close Kin")
#ylim(0,0.4)
print(CKpair)
readline(prompt = "pause ")
DKpair <- ggplot(data, aes(x= as.factor(isPost), y=eo.dk, fill=as.factor(isPost) ))+
geom_boxplot()+
geom_jitter(position = position_jitter(0.2), alpha = 0.5)+
ggtitle(paste("Distant Kin Pair preference pre- vs. post- hurricane ",groupyear[gy],sep=""))+
labs(fill = "Hurricane Status",x="Hurricane Status",y="Obs./Exp. Distant Kin")
#ylim(0,0.4)
print(DKpair)
readline(prompt = "pause ")
Upair <- ggplot(data, aes(x= as.factor(isPost), y=eo.u, fill=as.factor(isPost) ))+
geom_boxplot()+
geom_jitter(position = position_jitter(0.2), alpha = 0.5)+
ggtitle(paste("Unrelated Pair preference pre- vs. post- hurricane ",groupyear[gy],sep=""))+
labs(fill = "Hurricane Status",x="Hurricane Status",y="Obs./Exp. Unrelated")
#ylim(0,0.4)
print(Upair)
readline(prompt = "pause ")
}
library(lme4)# Generalized Linear Mixed Models
library(lmerTest)
library(performance)
#library(sjPlot)
#library(glmmTMB)# Generalized Linear Mixed Models, other package
#library(MCMCglmm)# Generalized Linear Mixed Models, other package
#library(bbmle)#Tools for General Maximum Likelihood Estimation
#library(DHARMa) #residual diagnostic fr hierarchical (multi-level/mixed) regression models
#Load data
load("C:/Users/Camille Testard/Documents/GitHub/Cayo-Maria/Social_Network_Analysis/SocialCapital.dSocialRates.RData")
#Format data correclty
SocialCapital.ALL$sex = as.factor(SocialCapital.ALL$sex); SocialCapital.ALL$age = as.numeric(SocialCapital.ALL$age); SocialCapital.ALL$group = as.factor(SocialCapital.ALL$group)
data = SocialCapital.ALL[-which(is.na(SocialCapital.ALL$dpAcc)),] #remove NA
#check distribution of independent variables
hist(data$dpAcc); hist(data$dpSocial, add=T)
#Scale parameters:
data[,c("age","GroomIN","GroomOUT","AggIN","AggOUT","vig.ra","sdb.ra")] <- scale(data[,c("age","GroomIN","GroomOUT","AggIN","AggOUT","vig.ra","sdb.ra")])
## Model Social Capital effect on change in sociliaty rates
#Modelling change in p(Acc)
dpAcc1 <- lmer(dpAcc~ sex + age + group + rank + (1|id) + (1|year), data = data)
summary(dpAcc1)
tab_model(dpAcc1)
install.packages("tsna",dependencies = T)
install.packages("ndtv",dependencies = T)
#generate_corr.dprox.dgroom
#Are the individuals who spend more time in proximity also those that change their grooming
#freq. the most?
#Load libraries
library(ggplot2)
library(ggpubr)
library(matlab)
#Load data
load("C:/Users/Camille Testard/Documents/Github/Cayo-Maria/R.Data/ChangeP.RData")
correl.coeff=vector()
iter=1
dprob.iter=dprob.ALL[dprob.ALL$iter==iter,]
corr.plot <- ggplot(dprob.iter,aes(dpAcc, dpSocial)) +
geom_point(color='blue')+
xlab("Change in Proximity")+ylab("Change in Grooming")+
ggtitle("Correlation between change in proximity and change in grooming")+
geom_smooth(method='lm', formula= y~x)
corr.plot
cor.test(dprob.iter$dpAcc,dprob.iter$dpSocial)
correl.coeff=vector(); iter=1
for (iter in 1:max(dprob.ALL$iter)){
print(paste("%%%%%%%%%%%%%%%%%%%%%%%%%%%% iter", iter, " %%%%%%%%%%%%%%%%%%%%%%%%%%%%"))
# dprob.iter=dprob.ALL[dprob.ALL$iter==iter,]
# #Plot change in prox vs. change in grooming
# corr.plot <- ggplot(dprob.iter,aes(dpAcc, dpSocial)) +
#   geom_point(color='blue')+
#   xlab("Change in Proximity")+ylab("Change in Grooming")+
#   ggtitle("Correlation between change in proximity and change in grooming")+
#   geom_smooth(method='lm', formula= y~x)
correl <- cor.test(dprob.iter$dpAcc,dprob.iter$dpSocial) #compute correlation
correl.coeff[iter]=correl[["estimate"]]
}
#Find mean correlation coefficient and 95% CI
mean.corr = mean(correl.coeff)
CI = quantile(correl.coeff,probs=c(0.025, 0.975))
mean.corr
CI
#Load libraries
library(ggplot2)
library(ggpubr)
library(matlab)
#Load data
load("C:/Users/Camille Testard/Documents/Github/Cayo-Maria/R.Data/ChangeP.RData")
correl.coeff=vector(); iter=1
for (iter in 1:max(dprob.ALL$iter)){
print(paste("%%%%%%%%%%%%%%%%%%%%%%%%%%%% iter", iter, " %%%%%%%%%%%%%%%%%%%%%%%%%%%%"))
dprob.iter=dprob.ALL[dprob.ALL$iter==iter,]
# #Plot change in prox vs. change in grooming
# corr.plot <- ggplot(dprob.iter,aes(dpAcc, dpSocial)) +
#   geom_point(color='blue')+
#   xlab("Change in Proximity")+ylab("Change in Grooming")+
#   ggtitle("Correlation between change in proximity and change in grooming")+
#   geom_smooth(method='lm', formula= y~x)
correl <- cor.test(dprob.iter$dpAcc,dprob.iter$dpSocial) #compute correlation
correl.coeff[iter]=correl[["estimate"]]
}
mean.corr
CI
#generate_corr.dprox.dgroom
#Are the individuals who spend more time in proximity also those that change their grooming
#freq. the most?
#Load libraries
library(ggplot2)
library(ggpubr)
library(matlab)
#Load data
load("C:/Users/Camille Testard/Documents/Github/Cayo-Maria/R.Data/ChangeP.RData")
correl.coeff=vector(); iter=1
for (iter in 1:max(dprob.ALL$iter)){
print(paste("%%%%%%%%%%%%%%%%%%%%%%%%%%%% iter", iter, " %%%%%%%%%%%%%%%%%%%%%%%%%%%%"))
dprob.iter=dprob.ALL[dprob.ALL$iter==iter,]
# #Plot change in prox vs. change in grooming
# corr.plot <- ggplot(dprob.iter,aes(dpAcc, dpSocial)) +
#   geom_point(color='blue')+
#   xlab("Change in Proximity")+ylab("Change in Grooming")+
#   ggtitle("Correlation between change in proximity and change in grooming")+
#   geom_smooth(method='lm', formula= y~x)
correl <- cor.test(dprob.iter$dpAcc,dprob.iter$dpSocial) #compute correlation
correl.coeff[iter]=correl[["estimate"]]
}
mean.corr = mean(correl.coeff)
mean(correl.coeff)
CI = quantile(correl.coeff,probs=c(0.025, 0.975))
CI
load("C:/Users/Camille Testard/Desktop/Desktop-Cayo-Maria/subsampled_idx.RData")
plot(uniqueIdx.post, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 75000),
main="# Unique observations as a function of subsampling iteration")
# segments(x0=0,x1=length(uniqueIdx.post), y0=expected.numObs.post,y1=expected.numObs.post, col="red")
segments(x0=0,x1=length(uniqueIdx.post), y0=post.all,y1=post.all, col="blue")
legend("bottomright",legend="full #Obs", lty=1,col="blue")
#find the number of UNIQUE observations pre and post. What % of the data is represented?
length(unique(subsampled.idx.pre))/pre.all # 83.4%
length(unique(subsampled.idx.post))/post.all # 90.8%
total_obs = length(unique(subsampled.idx.pre))+ length(unique(subsampled.idx.post))
perc_total_obs = total_obs/(pre.all + post.all)
#Find the difference between the actual #observations vs. the expected
expected.numObs.pre-length(unique(subsampled.idx.pre))
expected.numObs.post-length(unique(subsampled.idx.post))
#Find the number of observations you would expect to see deleted based on absence of observation in one category pre- or post.
FullScans$subsampling_cat = paste(FullScans$focalID,FullScans$Q,FullScans$timeBlock,sep=".")
t=table(as.character(FullScans$subsampling_cat),FullScans$isPost)
numObs_deleted_pre = sum(t[which(t[,2]==0),1])
numObs_deleted_post = sum(t[which(t[,1]==0),2])
expected.numObs.pre = pre.all-numObs_deleted_pre
expected.numObs.post = post.all-numObs_deleted_post
#Generate Random SubSampled Scans
setwd("C:/Users/Camille Testard/Documents/Github/Cayo-Maria/")
source("cleaned_code/Functions/CalcSubsampledScans.R")
setwd("C:/Users/Camille Testard/Desktop/Desktop-Cayo-Maria/")
allScans = read.csv("Behavioral_Data/Data All Cleaned/allScans.txt")
###########################################################################
## FULL DATA
#Select groups of interest
PrePostScans =  allScans[which(as.character(allScans$group) == "V" | as.character(allScans$group) == "KK"),]
SubScans=PrePostScans[-which(PrePostScans$year==2019),] #remove 2019
unqIDs = as.character(unique(SubScans$focalID))
#Exclude individuals that are not present either pre-hurricane or post-hurricane
for (id in 1:length(unqIDs)){ #For all individuals
if (length(which(SubScans$focalID == unqIDs[id] & SubScans$isPost == 0))==0
| length(which(SubScans$focalID == unqIDs[id] & SubScans$isPost == 1))==0) {
SubScans=SubScans[-which(SubScans$focalID == unqIDs[id]),]
}
}
FullScans=SubScans
# Run checks to have a better idea of how the data is sampled when there is no subsampling
pre.all = length(which(FullScans$isPost==0)); post.all=length(which(FullScans$isPost==1)) #Check the number of observations pre (0) and post (1)
unqIDs = as.character(unique(FullScans$focalID)) #Check the number of unique IDs
full.sample.table = table(as.character(FullScans$focalID),FullScans$isPost)#Check the number of observation by ID pre- vs. Post.
write.csv(full.sample.table,"C:/Users/Camille Testard/Desktop/Desktop-Cayo-Maria/full.sample.table2")
#Find the number of observations you would expect to see deleted based on absence of observation in one category pre- or post.
FullScans$subsampling_cat = paste(FullScans$focalID,FullScans$Q,FullScans$timeBlock,sep=".")
t=table(as.character(FullScans$subsampling_cat),FullScans$isPost)
numObs_deleted_pre = sum(t[which(t[,2]==0),1])
numObs_deleted_post = sum(t[which(t[,1]==0),2])
expected.numObs.pre = pre.all-numObs_deleted_pre
expected.numObs.post = post.all-numObs_deleted_post
load("C:/Users/Camille Testard/Desktop/Desktop-Cayo-Maria/subsampled_idx.RData")
#find the number of UNIQUE observations pre and post. What % of the data is represented?
length(unique(subsampled.idx.pre))/pre.all # 83.4%
length(unique(subsampled.idx.post))/post.all # 90.8%
total_obs = length(unique(subsampled.idx.pre))+ length(unique(subsampled.idx.post))
perc_total_obs = total_obs/(pre.all + post.all)
#Find the difference between the actual #observations vs. the expected
expected.numObs.pre-length(unique(subsampled.idx.pre))
expected.numObs.post-length(unique(subsampled.idx.post))
plot(uniqueIdx.post, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 75000),
main="# Unique observations as a function of subsampling iteration")
# segments(x0=0,x1=length(uniqueIdx.post), y0=expected.numObs.post,y1=expected.numObs.post, col="red")
segments(x0=0,x1=length(uniqueIdx.post), y0=post.all,y1=post.all, col="blue")
legend("bottomright",legend="full #Obs", lty=1,col="blue")
plot(uniqueIdx.pre, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 25000),xlim=c(0,100),
main="Pre-Hurricane: #unique observations as a function of subsampling iteration")
# segments(x0=0,x1=length(uniqueIdx.pre), y0=expected.numObs.pre,y1=expected.numObs.pre, col="red")
segments(x0=0,x1=length(uniqueIdx.pre), y0=pre.all,y1=pre.all, col="blue")
legend("bottomright",legend="full #Obs pre-hurr.", lty=1,col="blue")
uniqueIdx.pre
plot(uniqueIdx.pre, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 25000),xlim=c(0,100),
main="Pre-Hurricane: #unique observations as a function of subsampling iteration")
# segments(x0=0,x1=length(uniqueIdx.pre), y0=expected.numObs.pre,y1=expected.numObs.pre, col="red")
segments(x0=0,x1=length(uniqueIdx.pre), y0=pre.all,y1=pre.all, col="blue")
segments(x0=63, x1=63, y0=0, y1=max(uniqueIdx.pre), col=red, lty=2)
legend("bottomright",legend="full #Obs pre-hurr.", lty=1,col="blue")
plot(uniqueIdx.pre, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 25000),xlim=c(0,100),
main="Pre-Hurricane: #unique observations as a function of subsampling iteration")
# segments(x0=0,x1=length(uniqueIdx.pre), y0=expected.numObs.pre,y1=expected.numObs.pre, col="red")
segments(x0=0,x1=length(uniqueIdx.pre), y0=pre.all,y1=pre.all, col="blue")
segments(x0=64, x1=64, y0=0, y1=max(uniqueIdx.pre), col="red", lty=2)
legend("bottomright",legend="full #Obs pre-hurr.", lty=1,col="blue")
#For pre-hurricane data: 64 iterations
legend("bottomright",legend=c("full #Obs post-hurr.","# iterations required to max #obs"), lty=c(1,2),col=c("blue","red"))
plot(uniqueIdx.pre, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 25000),xlim=c(0,200),
main="Pre-Hurricane: #unique observations as a function of subsampling iteration")
# segments(x0=0,x1=length(uniqueIdx.pre), y0=expected.numObs.pre,y1=expected.numObs.pre, col="red")
segments(x0=0,x1=length(uniqueIdx.pre), y0=pre.all,y1=pre.all, col="blue")
segments(x0=64, x1=64, y0=0, y1=max(uniqueIdx.pre), col="red", lty=2)
legend("bottomright",legend="full #Obs pre-hurr.", lty=1,col="blue")
plot(uniqueIdx.pre, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 25000),xlim=c(0,200),
main="Pre-Hurricane: #unique observations as a function of subsampling iteration")
# segments(x0=0,x1=length(uniqueIdx.pre), y0=expected.numObs.pre,y1=expected.numObs.pre, col="red")
segments(x0=0,x1=length(uniqueIdx.pre), y0=pre.all,y1=pre.all, col="blue")
segments(x0=64, x1=64, y0=0, y1=max(uniqueIdx.pre), col="red", lty=2)
legend("bottomright",legend=c("full #Obs post-hurr.","# iterations required to max #obs"), lty=c(1,2),col=c("blue","red"))
#For pre-hurricane data: 64 iterations
plot(uniqueIdx.post, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 75000),
main="Post-Hurricane: # Unique observations as a function of subsampling iteration")
# segments(x0=0,x1=length(uniqueIdx.post), y0=expected.numObs.post,y1=expected.numObs.post, col="red")
segments(x0=0,x1=length(uniqueIdx.post), y0=post.all,y1=post.all, col="blue")
segments(x0=275, x1=275, y0=0, y1=max(uniqueIdx.pre), col="red", lty=2)
legend("bottomright",legend=c("full #Obs post-hurr.","# iterations required to max #obs"), lty=c(1,2),col=c("blue","red"))
#For post-hurricane data: 275 iterations
plot(uniqueIdx.post, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 75000),xlim=c(0,500),
main="Post-Hurricane: # Unique observations as a function of subsampling iteration")
# segments(x0=0,x1=length(uniqueIdx.post), y0=expected.numObs.post,y1=expected.numObs.post, col="red")
segments(x0=0,x1=length(uniqueIdx.post), y0=post.all,y1=post.all, col="blue")
segments(x0=275, x1=275, y0=0, y1=max(uniqueIdx.post), col="red", lty=2)
legend("bottomright",legend=c("full #Obs post-hurr.","# iterations required to max #obs"), lty=c(1,2),col=c("blue","red"))
#For post-hurricane data: 275 iterations
plot(uniqueIdx.post, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 75000),xlim=c(0,350),
main="Post-Hurricane: # Unique observations as a function of subsampling iteration")
# segments(x0=0,x1=length(uniqueIdx.post), y0=expected.numObs.post,y1=expected.numObs.post, col="red")
segments(x0=0,x1=length(uniqueIdx.post), y0=post.all,y1=post.all, col="blue")
segments(x0=275, x1=275, y0=0, y1=max(uniqueIdx.post), col="red", lty=2)
legend("bottomright",legend=c("full #Obs post-hurr.","# iterations required to max #obs"), lty=c(1,2),col=c("blue","red"))
#Plot the number of UNIQUE observations as a function of the number of iterations
#How many subsampling iterations do we need to ensure all the data is used?
plot(uniqueIdx.pre, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 25000),xlim=c(0,200),
main="Pre-Hurricane: #unique observations as a function of subsampling iteration")
# segments(x0=0,x1=length(uniqueIdx.pre), y0=expected.numObs.pre,y1=expected.numObs.pre, col="red")
segments(x0=0,x1=length(uniqueIdx.pre), y0=pre.all,y1=pre.all, col="blue")
segments(x0=64, x1=64, y0=0, y1=max(uniqueIdx.pre), col="red", lty=2)
legend("bottomleft",legend=c("full #Obs post-hurr.","# iterations required to max #obs"), lty=c(1,2),col=c("blue","red"))
#For pre-hurricane data: 64 iterations
#How many subsampling iterations do we need to ensure all the data is used?
plot(uniqueIdx.pre, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 25000),xlim=c(0,200),
main="Pre-Hurricane: #unique observations as a function of subsampling iteration")
# segments(x0=0,x1=length(uniqueIdx.pre), y0=expected.numObs.pre,y1=expected.numObs.pre, col="red")
segments(x0=0,x1=length(uniqueIdx.pre), y0=pre.all,y1=pre.all, col="blue")
segments(x0=64, x1=64, y0=0, y1=max(uniqueIdx.pre), col="red", lty=2)
legend("bottomright",legend=c("full #Obs post-hurr.","# iterations required to max #obs"), lty=c(1,2),col=c("blue","red"))
#For pre-hurricane data: 64 iterations
plot(uniqueIdx.post, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 75000),xlim=c(0,350),
main="Post-Hurricane: # Unique observations as a function of subsampling iteration")
# segments(x0=0,x1=length(uniqueIdx.post), y0=expected.numObs.post,y1=expected.numObs.post, col="red")
segments(x0=0,x1=length(uniqueIdx.post), y0=post.all,y1=post.all, col="blue")
segments(x0=275, x1=275, y0=0, y1=max(uniqueIdx.post), col="red", lty=2)
legend("bottomleft",legend=c("full #Obs post-hurr.","# iterations required to max #obs"), lty=c(1,2),col=c("blue","red"))
#For post-hurricane data: 275 iterations
plot(uniqueIdx.post, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 75000),xlim=c(0,350),
main="Post-Hurricane: # Unique observations as a function of subsampling iteration", cex=1.5)
plot(uniqueIdx.post, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 75000),xlim=c(0,350),
main="Post-Hurricane: # Unique observations as a function of subsampling iteration", cex=1.5)
plot(uniqueIdx.post, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 75000),xlim=c(0,350),
main="Post-Hurricane: # Unique observations as a function of subsampling iteration", cex=5)
plot(uniqueIdx.post, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 75000),xlim=c(0,350),
main="Post-Hurricane: # Unique observations as a function of subsampling iteration", cex.lab=1.5)
help("par")
plot(uniqueIdx.post, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 75000),xlim=c(0,350),
main="Post-Hurricane: # Unique observations as a function of subsampling iteration",
cex.lab=1.5, cex.main=1.5, cex.axis=1.25)
segments(x0=0,x1=length(uniqueIdx.post), y0=post.all,y1=post.all, col="blue")
segments(x0=275, x1=275, y0=0, y1=max(uniqueIdx.post), col="red", lty=2)
legend("bottomleft",legend=c("full #Obs post-hurr.","# iterations required to max #obs"), lty=c(1,2),col=c("blue","red"))
legend("bottomleft",legend=c("full #Obs post-hurr.","# iterations required to max #obs"), lty=c(1,2),col=c("blue","red"), cex=1.5)
plot(uniqueIdx.post, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 75000),xlim=c(0,350),
main="Post-Hurricane: # Unique observations as a function of subsampling iteration",
cex.lab=1.5, cex.main=1.5, cex.axis=1.25)
# segments(x0=0,x1=length(uniqueIdx.post), y0=expected.numObs.post,y1=expected.numObs.post, col="red")
segments(x0=0,x1=length(uniqueIdx.post), y0=post.all,y1=post.all, col="blue")
segments(x0=275, x1=275, y0=0, y1=max(uniqueIdx.post), col="red", lty=2, lwd=2)
legend("bottomleft",legend=c("full #Obs post-hurr.","# iterations required to max #obs"), lty=c(1,2),col=c("blue","red"), cex=1.5)
#For post-hurricane data: 275 iterations
plot(uniqueIdx.post, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 75000),xlim=c(0,350),
main="Post-Hurricane: # Unique observations as a function of subsampling iteration",
cex.lab=1.5, cex.main=1.5, cex.axis=1.25)
# segments(x0=0,x1=length(uniqueIdx.post), y0=expected.numObs.post,y1=expected.numObs.post, col="red")
segments(x0=0,x1=length(uniqueIdx.post), y0=post.all,y1=post.all, col="blue", lwd=2)
segments(x0=275, x1=275, y0=0, y1=max(uniqueIdx.post), col="red", lty=2, lwd=2)
legend("bottomleft",legend=c("full #Obs post-hurr.","# iterations required to max #obs"),
lwd=c(2,2), lty=c(1,2),col=c("blue","red"), cex=1.5)
plot(uniqueIdx.pre, ylab="# unique observations",xlab="Iteration of subsampling",ylim=c(0, 25000),xlim=c(0,200),
main="Pre-Hurricane: #unique observations as a function of subsampling iteration",
cex.lab=1.5, cex.main=1.5, cex.axis=1.25)
# segments(x0=0,x1=length(uniqueIdx.pre), y0=expected.numObs.pre,y1=expected.numObs.pre, col="red")
segments(x0=0,x1=length(uniqueIdx.pre), y0=pre.all,y1=pre.all, col="blue", lwd=2)
segments(x0=64, x1=64, y0=0, y1=max(uniqueIdx.pre), col="red", lty=2, lwd=2)
legend("bottomright",legend=c("full #Obs post-hurr.","# iterations required to max #obs"),
lwd=c(2,2),lty=c(1,2),col=c("blue","red"), cex=1.5)
#For pre-hurricane data: 64 iterations
#Load libraries
library(jtools)
library(ggplot2)
library(dplyr)
#Load data
setwd("C:/Users/Camille Testard/Documents/Github/Cayo-Maria/")
load("R.Data/SocialCapital.RData")
load("R.Data/ChangeP.RData")
data=dprob.ALL
data[,c("sex","age","percentrank")]= SocialCapital.ALL[match(dprob.ALL$id,SocialCapital.ALL$id),c("sex","age","percentrank")]#combine dprob and social capital (should be in exactly the same row order (by id))
setwd("C:/Users/Camille Testard/Desktop/Desktop-Cayo-Maria/Results/ChangePAccPSoc")
mean(data$dpSocial); sd(data$dpSocial)
mean(data$dpAcc); sd(data$dpAcc)
hist(data$dpSocial,col=rgb(0,1,1,0.5), breaks=20,main="Change p(Groom)",xlab="Change p(Groom) pre-to-post hurricane", xlim=c(-0.25,0.25))
segments(x0=0,y0=0,x1=0,y1=25000,col="red",lwd=4, lty=2)
box()
hist(data$dpSocial,col=rgb(0,1,1,0.5), breaks=50,main="Change p(Groom)",xlab="Change p(Groom) pre-to-post hurricane", xlim=c(-0.25,0.25))
segments(x0=0,y0=0,x1=0,y1=25000,col="red",lwd=4, lty=2)
box()
hist(data$dpSocial,col=rgb(0,1,1,0.5), breaks=40,main="Change p(Groom)",xlab="Change p(Groom) pre-to-post hurricane", xlim=c(-0.25,0.25))
segments(x0=0,y0=0,x1=0,y1=25000,col="red",lwd=4, lty=2)
box()
hist(data$dpSocial,col=rgb(0,1,1,0.5), breaks=60,main="Change p(Groom)",xlab="Change p(Groom) pre-to-post hurricane", xlim=c(-0.25,0.25))
segments(x0=0,y0=0,x1=0,y1=25000,col="red",lwd=4, lty=2)
box()
hist(data$dpAcc,col=rgb(0,1,1,0.5), breaks=60,main="Change p(Proximity)",xlab="Change p(Proximity) pre-to-post hurricane", xlim=c(-0.25,1))
segments(x0=0,y0=0,x1=0,y1=25000,col="red",lwd=4, lty=2)
box()
hist(data$dpSocial,col=rgb(0,1,1,0.5), breaks=60,main="Change p(Groom)",xlab="Change p(Groom) pre-to-post hurricane", xlim=c(-0.25,0.25))
segments(x0=0,y0=0,x1=0,y1=25000,col="red",lwd=4, lty=2)
box()
hist(data$dpAcc,col=rgb(0,1,1,0.5), breaks=60,main="Change p(Proximity)",xlab="Change p(Proximity) pre-to-post hurricane", xlim=c(-0.25,1))
segments(x0=0,y0=0,x1=0,y1=25000,col="red",lwd=4, lty=2)
box()
hist(data$dpSocial,col=rgb(0,1,1,0.5), breaks=80,main="Change p(Groom)",xlab="Change p(Groom) pre-to-post hurricane", xlim=c(-0.25,0.25))
segments(x0=0,y0=0,x1=0,y1=25000,col="red",lwd=4, lty=2)
box()
hist(data$dpAcc,col=rgb(0,1,1,0.5), breaks=60,main="Change p(Proximity)",xlab="Change p(Proximity) pre-to-post hurricane", xlim=c(-0.25,1))
segments(x0=0,y0=0,x1=0,y1=25000,col="red",lwd=4, lty=2)
box()
hist(data$dpSocial,col=rgb(0,1,1,0.5), breaks=80,main="Change p(Groom)",xlab="Change p(Groom) pre-to-post hurricane")#, xlim=c(-0.25,0.25))
segments(x0=0,y0=0,x1=0,y1=25000,col="red",lwd=4, lty=2)
box()
hist(data$dpSocial,col=rgb(0,1,1,0.5), breaks=80,main="Change p(Groom)",xlab="Change p(Groom) pre-to-post hurricane", xlim=c(-0.25,0.25))
segments(x0=0,y0=0,x1=0,y1=25000,col="red",lwd=4, lty=2)
box()
hist(data$dpSocial,col=rgb(0,1,1,0.5), breaks=100,main="Change p(Groom)",xlab="Change p(Groom) pre-to-post hurricane", xlim=c(-0.25,0.25))
segments(x0=0,y0=0,x1=0,y1=25000,col="red",lwd=4, lty=2)
box()
hist(data$dpSocial,col=rgb(0,1,1,0.5), breaks=60,main="Change p(Groom)",xlab="Change p(Groom) pre-to-post hurricane", xlim=c(-0.25,0.25))
segments(x0=0,y0=0,x1=0,y1=25000,col="red",lwd=4, lty=2)
box()
#Load data
setwd("C:/Users/Camille Testard/Documents/Github/Cayo-Maria/")
source("cleaned_code/Functions/CalcSubsampledScans.R")
setwd("C:/Users/Camille Testard/Desktop/Desktop-Cayo-Maria/")
allScans = read.csv("Behavioral_Data/Data All Cleaned/allScans.txt")
#Set parameters:
num_iter = 500; iter =1
only2017=F; #if only considering 2017 (year just prior hurricane). Note: there is  no V2017 valid dp(groom) & dp(prox) because they all have less than 20 obs.
group = c("KK","KK","V", "V", "V")
years = c(2015,2017,2015,2016,2017)
groupyears = c("KK2015", "KK2017","V2015", "V2016", "V2017")
dprob.ALL = data.frame();
for (iter in 1:num_iter){
print(paste("%%%%%%%%%%%%%%%%%% iter",iter, "%%%%%%%%%%%%%%%%%%"))
#####################################################################
# 1. Compute change in p(Acc) and p(Social), per individual, per year
#####################################################################
#Calculate random subsamples
randomScans = calcRandomScans(allScans)
gy=1
for (gy in 1:length(groupyears)){
rscans = randomScans[which(randomScans$year == years[gy] & randomScans$group == group[gy]),]
#Load data
setwd("C:/Users/Camille Testard/Desktop/Desktop-Cayo-Maria/Behavioral_Data/Data All Cleaned")
meta_data = read.csv(paste("Group",groupyears[gy],"_GroupByYear.txt", sep = ""))
unqIDs = as.character(meta_data$id)
dprob=data.frame(matrix(NA, nrow=length(unqIDs),ncol=4)); colnames(dprob)=c("id","dpAcc","dpSocial","num_obs")
for (id in 1:length(unqIDs)){ #For all individuals
isProx.pre = rscans$isProx[which(as.character(rscans$focalID) == unqIDs[id] & rscans$isPost == 0)] #get all pre-hurricane data for that individuals
isProx.post = rscans$isProx[which(as.character(rscans$focalID) == unqIDs[id] & rscans$isPost == 1)]#get all post-re-hurricane data for that individuals
isSocial.pre = rscans$isSocial[which(as.character(rscans$focalID) == unqIDs[id] & rscans$isPost == 0)] #get all pre-hurricane data for that individuals
isSocial.post = rscans$isSocial[which(as.character(rscans$focalID) == unqIDs[id] & rscans$isPost == 1)]#get all post-re-hurricane data for that individuals
dpAcc=NA; dpSocial=NA; num_obs = length(isProx.pre)
if (length(isProx.pre)>=20) { #If there are more than 10 observations for that individual
pACC.pre = sum(isProx.pre)/length(isProx.pre)
pACC.post = sum(isProx.post)/length(isProx.post)
dpAcc = pACC.post - pACC.pre
pSocial.pre = sum(isSocial.pre)/length(isSocial.pre)
pSocial.post = sum(isSocial.post)/length(isSocial.post)
dpSocial = pSocial.post - pSocial.pre
} #end of min obs clause
dprob[id,]=c(unqIDs[id],dpAcc,dpSocial,num_obs)
} #end of id for loop
dprob$group = group[gy]; dprob$year = years[gy]; dprob$iter=iter
dprob.ALL = rbind(dprob.ALL, dprob)
} #end of groupyear for loop
}
dprob.ALL$dpAcc=as.numeric(dprob.ALL$dpAcc)
dprob.ALL$dpSocial=as.numeric(dprob.ALL$dpSocial)
if (length(which(is.na(dprob.ALL$dpAcc)))!=0) {dprob.ALL = dprob.ALL[-which(is.na(dprob.ALL$dpAcc)),]} #remove NA
setwd("C:/Users/Camille Testard/Documents/Github/Cayo-Maria/R.Data")
save(dprob.ALL,file="ChangeP_min20.RData")
# load("C:/Users/Camille Testard/Documents/Github/Cayo-Maria/R.Data/ChangeP.RData")
# length(unique(dprob.ALL$id))
#Load data
setwd("C:/Users/Camille Testard/Documents/Github/Cayo-Maria/")
load("R.Data/SocialCapital.RData")
load("R.Data/ChangeP_min20.RData")
data=dprob.ALL
data[,c("sex","age","percentrank")]= SocialCapital.ALL[match(dprob.ALL$id,SocialCapital.ALL$id),c("sex","age","percentrank")]#combine dprob and social capital (should be in exactly the same row order (by id))
#####################################################################
# 3. Visualizations
#####################################################################
setwd("C:/Users/Camille Testard/Desktop/Desktop-Cayo-Maria/Results/ChangePAccPSoc")
hist(data$dpSocial,col=rgb(0,1,1,0.5), breaks=60,main="Distribution of the change in p(groom) pre-to-post hurricane",xlab="Change p(Groom) pre-to-post hurricane", xlim=c(-0.25,0.25))
segments(x0=0,y0=0,x1=0,y1=25000,col="red",lwd=4, lty=2)
box()
hist(data$dpSocial,col=rgb(0,1,1,0.5), breaks=40,main="Distribution of the change in p(groom) pre-to-post hurricane",xlab="Change p(Groom) pre-to-post hurricane", xlim=c(-0.25,0.25))
segments(x0=0,y0=0,x1=0,y1=25000,col="red",lwd=4, lty=2)
box()
setwd("C:/Users/Camille Testard/Documents/Github/Cayo-Maria/")
load("R.Data/SocialCapital.RData")
load("R.Data/ChangeP.RData")
#Load data
setwd("C:/Users/Camille Testard/Documents/Github/Cayo-Maria/")
load("R.Data/SocialCapital.RData")
load("R.Data/ChangeP.RData")
data=dprob.ALL
data[,c("sex","age","percentrank")]= SocialCapital.ALL[match(dprob.ALL$id,SocialCapital.ALL$id),c("sex","age","percentrank")]#combine dprob and social capital (should be in exactly the same row order (by id))
mean(data$dpSocial); sd(data$dpSocial)
mean(data$dpAcc); sd(data$dpAcc)

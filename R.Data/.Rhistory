summary(bmASR)
rm(list = ls())# clear all variables
data <- read.csv("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Social_Cog_X_Social_Network/GazeData_Networks_noNAN.csv")
names(data)[1]<-"ID"
str(data)
bmASR <- lmer(Latency ~ Sex+ Age + Trial * percent.rank + (1|ID), data = data)
summary(bmASR)
#Looking at the effect of rank on individuals who completed the same number of trials
rm(list = ls())# clear all variables
data <- read.csv("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Social_Cog_X_Social_Network/GazeData_Networks_noNAN_3trial.csv") # include only individuals who completed 3 trials
names(data)[1]<-"ID"
bmR <- glm(Look ~ Trial * ord.rank , data = data, family = binomial)
summary(bmR)
bmSAG <- glmer(Look ~ Sex + Age + Trial*z.G.S + (1|ID), data = data, family = binomial)
summary(bmSAG)
bmSARG <- glmer(Look ~ Sex + Age + percent.rank + Trial*z.G.S + (1|ID), data = data, family = binomial)
summary(bmSARG)
bmSAP <- glmer(Look ~ Sex + Age + percent.rank +Trial*n.social.partners + (1|ID), data = data, family = binomial)
summary(bmSAP)
# Load all trials data:
rm(list = ls())# clear all variables
data <- read.csv("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Social_Cog_X_Social_Network/GazeData_Networks_SEA_noNAN.csv")
names(data)[1]<-"ID"
# load required libraries
library(lme4)
library(afex)
bmSAP <- glmer(Look ~ Sex + Age + percent.rank +Trial*n.social.partners + (1|ID), data = data, family = binomial)
summary(bmSAP)
bmSAW <- glmer(Look ~ Sex + Age + percent.rank + Trial*n.weak.connections + (1|ID), data = data, family = binomial)
summary(bmSAW)
bmSAC <- glmer(Look ~ Sex + Age + percent.rank + Trial*CompositeSocialityIndex + (1|ID), data = data, family = binomial)
summary(bmSAC)
bmSAT <- glmer(Look ~ Sex + Age + percent.rank + Trial*CSI.to.Top3 + (1|ID), data = data, family = binomial)
summary(bmSAT)
data = read.table('C:\Users\Camille Testard\Desktop\Behavioral_Ecology\Research_projects\Behavior_DataFiles2016\GroupHH2016_AgonisticActions.txt')
data = read.table('C:\Users\Camille Testard\Desktop\Behavioral_Ecology\Research_projects\Behavior_DataFiles2016\GroupHH2016_AgonisticActions.txt', header = TRUE, sep=",")
data = read.table(":\Users\Camille Testard\Desktop\Behavioral_Ecology\Research_projects\Behavior_DataFiles2016\GroupHH2016_AgonisticActions.txt", header = TRUE, sep=",")
data = read.table(":/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Behavior_DataFiles2016/GroupHH2016_AgonisticActions.txt", header = TRUE, sep=",")
data = read.table(":/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Behavior_DataFiles2016/GroupHH2016_AgonisticActions.txt")
data = read.table("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Behavior_DataFiles2016/GroupHH2016_AgonisticActions.txt")
data = read.table("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Behavior_DataFiles2016/GroupHH2016_AgonsiticActions.txt")
View(data)
View(data)
View(data)
View(data)
data = read.table("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Behavior_DataFiles2016/GroupHH2016_AgonsiticActions.txt", header=TRUE)
View(data)
data = read.table("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Behavior_DataFiles2016/GroupHH2016_AgonsiticActions.txt", header=TRUE, sep=",")
View(data)
data = read.table("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Behavior_DataFiles2016/GroupHH2016_FocalData.txt", header=TRUE, sep=",")
View(data)
View(data)
data = read.table("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Behavior_DataFiles2016/GroupHH2016_GroomingEvents.txt", header=TRUE, sep=",")
View(data)
rm(list = ls())# clear all variables
#Load data
data_grooming = read.table("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Behavior_DataFiles2016/GroupHH2016_GroomingEvents.txt", header=TRUE, sep=",")
data_proximity = read.table("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Behavior_DataFiles2016/GroupHH2016_ProximityGroups.txt", header=TRUE, sep=",")
View(data_proximity)
View(data_grooming)
data_group = read.table("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Behavior_DataFiles2016/GroupHH2016_GroupByYear.txt", header=TRUE, sep=",")
View(data_grooming)
View(data_grooming)
View(data_grooming)
View(data_group)
View(data_group)
install.packages("igraph", dependencies = TRUE)
install.packages("sna", dependencies = TRUE)
install.packages("tnet", dependencies = TRUE)
library(igraph)
library(sna)
library(tnet)
#Need to upload an adjacency matrix, rather than socprog style data...
#read adjacency matrix
data=read.csv("C:\Users\Camille Testard\Desktop\Behavioral_Ecology\Research_projects\Behavior_DataFiles2016\GroupHH2016_grooming_adjacency_matrix.csv",header=TRUE,row.names=1,check.names=FALSE) # choose an adjacency matrix from a .csv file
data=read.csv("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Behavior_DataFiles2016/GroupHH2016_grooming_adjacency_matrix.csv",header=TRUE,row.names=1,check.names=FALSE) # choose an adjacency matrix from a .csv file
rm(list = ls())# clear all variables
data=read.csv("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Behavior_DataFiles2016/GroupHH2016_grooming_adjacency_matrix.csv",header=TRUE,row.names=1,check.names=FALSE) # choose an adjacency matrix from a .csv file
View(data)
m=as.matrix(data)
View(m)
View(m)
demo(package="igraph")
help("igraph")
am.g=graph.adjacency(m,mode="directed",weighted=T)
View(am.g)
View(am.g)
am.g
A.Weightdeg<-degree(data)
ls()
A.Weightdeg
A.Weight.IN.deg <-degree(data, gmode="digraph", diag=FALSE, tmaxdev=FALSE, cmode="indegree", rescale=FALSE, ignore.eval=FALSE)
#weighted indegree
A.Weight.IN.deg <-degree(data, gmode="digraph", diag=FALSE, tmaxdev=FALSE, cmode="indegree", rescale=FALSE, ignore.eval=FALSE) #digraph = directed graph, cmode=type of degree centrality
#weighted outdegree
A.Weight.OUT.deg <-degree(data, gmode="digraph", diag=FALSE, tmaxdev=FALSE, cmode="outdegree", rescale=FALSE, ignore.eval=FALSE)
#Binary degree (inDegree)
A.Bindeg<-apply(data,2,function(a)sum(a>0))
A.Boutdeg<-apply(data,1,function(a)sum(a>0))
A.Bindeg
A.Boutdeg<-apply(data,1,function(a)sum(a>0))
rm(list = ls())# clear all variables
data <- read.csv("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Social_Cog_X_Social_Network/GazeData_Networks_noNAN_3trial.csv") # include only individuals who completed 3 trials
names(data)[1]<-"ID"
# two-way mixed ANOVA (both within and between subject)
aov2 <- aov(Look ~ Trial * ord.rank + Error(ID/Trial), data = data)
summary(aov2)
aov2 <- aov(Look ~ Trial * ord.rank, data = data)
summary(aov2)
install.packages("ggpubr", dependencies = TRUE)
xbar <- 159
n <- 1047
ns <- 100
M = matrix(rbinom(n*ns, size=1, prob=xbar/n), nrow=n)
#Load data
data_grooming = read.table("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Behavior_DataFiles2016/GroupHH2016_GroomingEvents.txt", header=TRUE, sep=",")
data_proximity = read.table("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Behavior_DataFiles2016/GroupHH2016_ProximityGroups.txt", header=TRUE, sep=",")
#C
View(data_proximity)
data_proximity.in.proximity(10)
data_proximity$in.proximity(10)
data_proximity$in.proximity
data_proximity$in.proximity[10]
View(data_proximity)
rm(list = ls())# clear all variables
library(igraph)
library(sna)
library(tnet)
#Need to upload an adjacency matrix, rather than socprog style data...
#read adjacency matrix
data=read.csv("C:/Users/Camille Testard/Desktop/Behavioral_Ecology/Research_projects/Behavior_DataFiles2016/GroupHH2016_CSI_adjacency_matrix.csv",header=TRUE,row.names=1,check.names=FALSE) # choose an adjacency matrix from a .csv file
m=as.matrix(data) # coerces the data set as a matrix
am.g=graph.adjacency(m,mode="directed",weighted=T) # this will create an directed 'igraph object'. Change qualifiers to make "undirected" or unweighted (null)
am.g
View(am.g)
#Get the network measures
#Weighted degree (Strength, undirected)
A.Weightdeg<-degree(data) #
A.Weightdeg
A.Weight.IN.deg <-degree(data, gmode="digraph", diag=FALSE, tmaxdev=FALSE, cmode="indegree", rescale=FALSE, ignore.eval=FALSE)
A.Weight.OUT.deg <-degree(data, gmode="digraph", diag=FALSE, tmaxdev=FALSE, cmode="outdegree", rescale=FALSE, ignore.eval=FALSE)
A.Weight.IN.deg
A.Weight.OUT.deg
A.Bindeg<-apply(data,2,function(a)sum(a>0))
A.Boutdeg<-apply(data,1,function(a)sum(a>0))
A.Clust<-transitivity(am.g,"local")
#clustering coeff (local). How close are the neighbors of a graph to be a clique (a complete graph). Are your friends also friends between each other?
A.Clust<-transitivity(am.g,"local") #from igraph package
#Weighted betweenness.The number of shortest paths that pass through the vertex.
A.Weight.between<-betweenness(data,gmode="graph",ignore.eval=F)
#Weighted eigenvector centrality
A.Weight.eig.cen<-evcent(data,gmode="graph",ignore.eval=F)
A.Weight.eig.cen<-evcent(data,gmode="graph",ignore.eval=F) #from 'sna' package
networkMeasures<-data.frame(cbind(A.Weightdeg,A.Weight.IN.deg,A.Weight.OUT.deg, A.Bindeg, A.Boutdeg, A.Clust,A.Weight.between,A.Weight.eig.cen))
write.table(networkMeasures, file = "A.2016HH_Centrality_Output.csv", sep = ",", col.names=T, row.names=T)
View(networkMeasures)
View(networkMeasures)
vcount(am.g)
vcount(am.g)^2.3
vcount(am.g)^2.8
V(am.g)
V(am.g)$label.cex <- 0.5
#increase space between nodes if overlapping
#fruchterman reingold layout
l <- layout.fruchterman.reingold(am.g,niter=500,area=vcount(am.g)^2.3,repulserad=vcount(am.g)^2.8)
#changes size of labels of vertices
V(am.g)$label.cex <- 0.5
View(l)
plot.igraph(am.g,layout=l, vertex.label=V(am.g)$name*2, vertex.color="CYAN1", vertex.size=7,edge.color="grey20",
edge.width=E(am.g)$weight*2,edge.arrow.size = 0.5)
plot.igraph(am.g,layout=l, vertex.label=V(am.g)$name, vertex.color="CYAN1", vertex.size=7,edge.color="grey20",
edge.width=E(am.g)$weight*2,edge.arrow.size = 0.5)
plot.igraph(am.g,layout=l, vertex.label=V(am.g)$name*0.5, vertex.color="CYAN1", vertex.size=7,edge.color="grey20",
edge.width=E(am.g)$weight*2,edge.arrow.size = 0.5)
plot.igraph(am.g,layout=l, vertex.label=V(am.g)$name*0.5, vertex.color="CYAN1", vertex.size=7,edge.color="grey20",
edge.width=E(am.g)$weight*2,edge.arrow.size = 0.5)
V(am.g)$name
plot.igraph(am.g,layout=l, vertex.label=V(am.g)$name, vertex.color="CYAN1", vertex.size=7,edge.color="grey20",
edge.width=E(am.g)$weight*2,edge.arrow.size = 0.5)
plot.igraph(am.g,layout=l, vertex.label=V(am.g)$name, vertex.color="CYAN1", vertex.size=7,edge.color="grey20",
edge.width=E(am.g)$weight*0.5,edge.arrow.size = 0.2)
plot.igraph(am.g,layout=l, vertex.label=V(am.g)$name, vertex.color="CYAN1", vertex.size=7,edge.color="grey20",
edge.width=E(am.g)$weight*0.2,edge.arrow.size = 0.2)
#fruchterman reingold layout
l <- layout.fruchterman.reingold(am.g,niter=500,area=vcount(am.g)^3.3,repulserad=vcount(am.g)^3.8)
#changes size of labels of vertices
V(am.g)$label.cex <- 0.5
plot.igraph(am.g,layout=l, vertex.label=V(am.g)$name, vertex.color="CYAN1", vertex.size=7,edge.color="grey20",
edge.width=E(am.g)$weight*0.2,edge.arrow.size = 0.2)
vcount(am.g)
vcount(am.g)^3.3
l <- layout.fruchterman.reingold(am.g,niter=500,area=vcount(am.g)^2,repulserad=vcount(am.g)^2.3)
#changes size of labels of vertices
V(am.g)$label.cex <- 0.5
#plot graph
plot.igraph(am.g,layout=l, vertex.label=V(am.g)$name, vertex.color="CYAN1", vertex.size=7,edge.color="grey20",
edge.width=E(am.g)$weight*0.2,edge.arrow.size = 0.2)
plot.igraph(am.g,layout=l, vertex.color="CYAN1", vertex.size=7,edge.color="grey20",
edge.width=E(am.g)$weight*2,edge.arrow.size = 0.5)
plot.igraph(am.g,layout=l, vertex.color="CYAN1", vertex.size=7,edge.color="grey20",
edge.width=E(am.g)$weight*0.2,edge.arrow.size = 0.2)
plot.igraph(am.g,layout=l, vertex.label=V(am.g)$name, vertex.color="CYAN1", vertex.size=7,edge.color="grey20",
edge.width=E(am.g)$weight*0.2,edge.arrow.size = 0.2)
plot.igraph(am.g,layout=l, vertex.label=V(am.g)$name, vertex.color="CYAN1", vertex.size=7,edge.color="grey20",
edge.width=E(am.g)$weight*0.2,edge.arrow.size = 0.2)
plot.igraph(am.g,layout=l, vertex.color="CYAN1", vertex.size=7,edge.color="grey20",
edge.width=E(am.g)$weight*0.2,edge.arrow.size = 0.2)
#spring embedded layout
s <- layout.spring(am.g, spring.length=1000,area=vcount(am.g)^2.3,repulserad=vcount(am.g)^2.8)
plot.igraph(am.g,layout=l, vertex.label=NA, vertex.color="orange", vertex.size=6,edge.color="grey20",edge.width=E(am.g)$weight*0.01)
plot.igraph(am.g,layout=l, vertex.label=NA, vertex.color="orange", vertex.size=6,edge.color="grey20",edge.width=E(am.g)$weight*0.01, edge.arrow.size = 0.2)
View(networkMeasures)
A.Weight.IN.deg
A.Weightdeg
A.Weight.OUT.deg
A.Weight.between
A.Weight.between
A.Weight.between<-betweenness(data,gmode="digraph",ignore.eval=F)
A.Weight.between
A.Weight.closenessn<-closeness(data,gmode="digraph",ignore.eval=F) #from 'sna' package
A.Weight.closeness<-closeness(data,gmode="digraph",ignore.eval=F) #from 'sna' package
A.Weight.closeness
A.Weight.closeness<-closeness(data,gmode="digraph",ignore.eval=F)
A.Weight.closeness
closeness(data,gmode="digraph",ignore.eval=F)
evcent(data,gmode="graph",ignore.eval=F)
closeness(data,gmode="graph",ignore.eval=F)
A.Weight.eig.cen<-evcent(data,gmode="digraph",ignore.eval=F)
A.Weight.eig.cen
A.Weight.eig.cen<-evcent(data,gmode="graph",ignore.eval=F)
A.Weight.eig.cen
install.packages("Perc", dependencies = TRUE)
install.packages("fitdistrplus", dependencies = TRUE)
load("C:/Users/Camille Testard/Documents/GitHub/Cayo-Maria/Social_Network_Analysis/ModelEffects.RData")
hist(NotAloneEffects$isPost)
hist(SocialEffects$isPost)
load("C:/Users/Camille Testard/Documents/GitHub/Cayo-Maria/Social_Network_Analysis/ModelEffects.RData")
hist(NotAloneEffects$isPost)
hist(SocialEffects$isPost)
load("C:/Users/Camille Testard/Documents/GitHub/Cayo-Maria/Social_Network_Analysis/ModelEffects.RData")
install.packages("gdata",dependencies = T)
keep(c("NotAlone.G.Effects","NotAlone.KK.Effects","NotAlone.V.Effects","NotAlone.S.Effects",
"NotAlone.Q.Effects","NotAlone.PM.Effects","NotAloneEffects","Social.G.Effects", "Social.KK.Effects",
"Social.V.Effects","Social.S.Effects","Social.Q.Effects","Social.PM.Effects","SocialEffects"))
gdata::keep(c("NotAlone.G.Effects","NotAlone.KK.Effects","NotAlone.V.Effects","NotAlone.S.Effects",
"NotAlone.Q.Effects","NotAlone.PM.Effects","NotAloneEffects","Social.G.Effects", "Social.KK.Effects",
"Social.V.Effects","Social.S.Effects","Social.Q.Effects","Social.PM.Effects","SocialEffects"))
c("NotAlone.G.Effects","NotAlone.KK.Effects","NotAlone.V.Effects","NotAlone.S.Effects",
"NotAlone.Q.Effects","NotAlone.PM.Effects","NotAloneEffects","Social.G.Effects", "Social.KK.Effects",
"Social.V.Effects","Social.S.Effects","Social.Q.Effects","Social.PM.Effects","SocialEffects")
rm(list=setdiff(ls(),c("NotAlone.G.Effects","NotAlone.KK.Effects","NotAlone.V.Effects","NotAlone.S.Effects",
"NotAlone.Q.Effects","NotAlone.PM.Effects","NotAloneEffects","Social.G.Effects", "Social.KK.Effects",
"Social.V.Effects","Social.S.Effects","Social.Q.Effects","Social.PM.Effects","SocialEffects")))
hist(NotAloneEffects$isPost)
hist(NotAloneEffects$isPost,add =F)
hist(SocialEffects$isPost,add =T)
load("C:/Users/Camille Testard/Documents/GitHub/Cayo-Maria/Social_Network_Analysis/ModelEffects.RData")
rm(list=setdiff(ls(),c("NotAlone.G.Effects","NotAlone.KK.Effects","NotAlone.V.Effects","NotAlone.S.Effects",
"NotAlone.Q.Effects","NotAlone.PM.Effects","NotAloneEffects","Social.G.Effects", "Social.KK.Effects",
"Social.V.Effects","Social.S.Effects","Social.Q.Effects","Social.PM.Effects","SocialEffects")))
#1. Show the distribution of the Hurricane effect on P(Acc) and P(Social) considering all data:
hist(NotAloneEffects$isPost,add =F)
hist(NotAloneEffects$isPost,add =F)
hist(SocialEffects$isPost,add =TRUE)
library(ggplot2)
load("C:/Users/Camille Testard/Documents/GitHub/Cayo-Maria/Social_Network_Analysis/AllStats3.RData")
AllStats[["KK.2013.1"]]= NULL
groupyear = c("V.2015","V.2016","V.2017","KK.2015","KK.2017")
gy=1
paste(c("GlobalNetworkMetrics",groupyear[gy],"pdf"),sep = ".")
paste("GlobalNetworkMetrics",groupyear[gy],"pdf",sep = ".")
groupyear = c("V.2015","V.2016","V.2017","KK.2015","KK.2017")
for (gy in 1:length(groupyear)){ #For each group
name.0 = paste(groupyear[gy],".0",sep="")
data.0 = AllStats[[name.0]]; data.0$isPost = 0
name.1 = paste(groupyear[gy],".1",sep="")
data.1 = AllStats[[name.1]]; data.1$isPost = 1
data= rbind(data.0, data.1)
pdf(file= paste("GlobalNetworkMetrics",groupyear[gy],"pdf",sep = "."), width=5, height=5, onefile = T) #width and height of the graphics region in inches. One file if true = multiple graphs in one file
#hist(data.0$dens); hist(data.1$dens)
{density <- ggplot(data, aes(x= as.factor(isPost), y=dens, fill=as.factor(isPost) ))+
geom_boxplot()+
geom_jitter(position = position_jitter(0.2), alpha = 0.5)+
ggtitle(paste("Density of social network pre- vs. post- hurricane ",groupyear[gy],sep=""))+
labs(fill = "Hurricane Status",x="Hurricane Status",y="Density of social network")}
#ylim(0,0.4)
# print(density)
# readline(prompt = "pause ")
#hist(data.0$gini); hist(data.1$gini)
{equity <- ggplot(data, aes(x= as.factor(isPost), y=gini, fill=as.factor(isPost) ))+
geom_boxplot()+
geom_jitter(position = position_jitter(0.2), alpha = 0.5)+
ggtitle(paste("Equity of social network pre- vs. post- hurricane ",groupyear[gy],sep=""))+
labs(fill = "Hurricane Status",x="Hurricane Status",y="Gini coeff relative to baseline")}
#ylim(0,0.9)
# print(equity)
# readline(prompt = "pause ")
}
library(ggplot2)
load("C:/Users/Camille Testard/Documents/GitHub/Cayo-Maria/Social_Network_Analysis/AllStats4.RData")
##########################################################
#Sex partner preference
##########################################################
groupyear = c("V.2015","V.2016","V.2017","KK.2015","KK.2017")
for (gy in 1:length(groupyear)){ #For each group
name.0 = paste(groupyear[gy],".0",sep="")
data.0 = AllStats[[name.0]]; data.0$isPost = 0
name.1 = paste(groupyear[gy],".1",sep="")
data.1 = AllStats[[name.1]]; data.1$isPost = 1
data= rbind(data.0, data.1)
pdf(file= paste("SexPartnerPref",groupyear[gy],"pdf",sep = "."), width=5, height=5, onefile = T)
{FFpair <- ggplot(data, aes(x= as.factor(isPost), y=eo.FF, fill=as.factor(isPost) ))+
geom_boxplot()+
geom_jitter(position = position_jitter(0.2), alpha = 0.5)+
ggtitle(paste("FF Pair preference pre- vs. post- hurricane ",groupyear[gy],sep=""))+
labs(fill = "Hurricane Status",x="Hurricane Status",y="Obs./Exp. FF")}
#ylim(0,0.4)
# print(FFpair)
# readline(prompt = "pause ")
{MMpair <- ggplot(data, aes(x= as.factor(isPost), y=eo.MM, fill=as.factor(isPost) ))+
geom_boxplot()+
geom_jitter(position = position_jitter(0.2), alpha = 0.5)+
ggtitle(paste("MM Pair preference pre- vs. post- hurricane ",groupyear[gy],sep=""))+
labs(fill = "Hurricane Status",x="Hurricane Status",y="Obs./Exp. MM")}
#ylim(0,0.4)
# print(MMpair)
# readline(prompt = "pause ")
{crosspair <- ggplot(data, aes(x= as.factor(isPost), y=eo.cross, fill=as.factor(isPost) ))+
geom_boxplot()+
geom_jitter(position = position_jitter(0.2), alpha = 0.5)+
ggtitle(paste("Cross Pair preference pre- vs. post- hurricane ",groupyear[gy],sep=""))+
labs(fill = "Hurricane Status",x="Hurricane Status",y="Obs./Exp. Cross")}
#ylim(0,0.4)
# print(crosspair)
# readline(prompt = "pause ")
}
##########################################################
#Kinship preference
##########################################################
for (gy in 1:length(groupyear)){ #For each group
name.0 = paste(groupyear[gy],".0",sep="")
data.0 = AllStats[[name.0]]; data.0$isPost = 0
name.1 = paste(groupyear[gy],".1",sep="")
data.1 = AllStats[[name.1]]; data.1$isPost = 1
data= rbind(data.0, data.1)
pdf(file= paste("KinshipPartnerPref",groupyear[gy],"pdf",sep = "."), width=5, height=5, onefile = T)
CKpair <- ggplot(data, aes(x= as.factor(isPost), y=eo.ck, fill=as.factor(isPost) ))+
geom_boxplot()+
geom_jitter(position = position_jitter(0.2), alpha = 0.5)+
ggtitle(paste("Close Kin Pair preference pre- vs. post- hurricane ",groupyear[gy],sep=""))+
labs(fill = "Hurricane Status",x="Hurricane Status",y="Obs./Exp. Close Kin")
#ylim(0,0.4)
print(CKpair)
readline(prompt = "pause ")
DKpair <- ggplot(data, aes(x= as.factor(isPost), y=eo.dk, fill=as.factor(isPost) ))+
geom_boxplot()+
geom_jitter(position = position_jitter(0.2), alpha = 0.5)+
ggtitle(paste("Distant Kin Pair preference pre- vs. post- hurricane ",groupyear[gy],sep=""))+
labs(fill = "Hurricane Status",x="Hurricane Status",y="Obs./Exp. Distant Kin")
#ylim(0,0.4)
print(DKpair)
readline(prompt = "pause ")
Upair <- ggplot(data, aes(x= as.factor(isPost), y=eo.u, fill=as.factor(isPost) ))+
geom_boxplot()+
geom_jitter(position = position_jitter(0.2), alpha = 0.5)+
ggtitle(paste("Unrelated Pair preference pre- vs. post- hurricane ",groupyear[gy],sep=""))+
labs(fill = "Hurricane Status",x="Hurricane Status",y="Obs./Exp. Unrelated")
#ylim(0,0.4)
print(Upair)
readline(prompt = "pause ")
}
library(lme4)# Generalized Linear Mixed Models
library(lmerTest)
library(performance)
#library(sjPlot)
#library(glmmTMB)# Generalized Linear Mixed Models, other package
#library(MCMCglmm)# Generalized Linear Mixed Models, other package
#library(bbmle)#Tools for General Maximum Likelihood Estimation
#library(DHARMa) #residual diagnostic fr hierarchical (multi-level/mixed) regression models
#Load data
load("C:/Users/Camille Testard/Documents/GitHub/Cayo-Maria/Social_Network_Analysis/SocialCapital.dSocialRates.RData")
#Format data correclty
SocialCapital.ALL$sex = as.factor(SocialCapital.ALL$sex); SocialCapital.ALL$age = as.numeric(SocialCapital.ALL$age); SocialCapital.ALL$group = as.factor(SocialCapital.ALL$group)
data = SocialCapital.ALL[-which(is.na(SocialCapital.ALL$dpAcc)),] #remove NA
#check distribution of independent variables
hist(data$dpAcc); hist(data$dpSocial, add=T)
#Scale parameters:
data[,c("age","GroomIN","GroomOUT","AggIN","AggOUT","vig.ra","sdb.ra")] <- scale(data[,c("age","GroomIN","GroomOUT","AggIN","AggOUT","vig.ra","sdb.ra")])
## Model Social Capital effect on change in sociliaty rates
#Modelling change in p(Acc)
dpAcc1 <- lmer(dpAcc~ sex + age + group + rank + (1|id) + (1|year), data = data)
summary(dpAcc1)
tab_model(dpAcc1)
install.packages("tsna",dependencies = T)
install.packages("ndtv",dependencies = T)
#generate_corr.dprox.dgroom
#Are the individuals who spend more time in proximity also those that change their grooming
#freq. the most?
#Load libraries
library(ggplot2)
library(ggpubr)
library(matlab)
#Load data
load("C:/Users/Camille Testard/Documents/Github/Cayo-Maria/R.Data/ChangeP.RData")
correl.coeff=vector()
iter=1
dprob.iter=dprob.ALL[dprob.ALL$iter==iter,]
corr.plot <- ggplot(dprob.iter,aes(dpAcc, dpSocial)) +
geom_point(color='blue')+
xlab("Change in Proximity")+ylab("Change in Grooming")+
ggtitle("Correlation between change in proximity and change in grooming")+
geom_smooth(method='lm', formula= y~x)
corr.plot
cor.test(dprob.iter$dpAcc,dprob.iter$dpSocial)
correl.coeff=vector(); iter=1
for (iter in 1:max(dprob.ALL$iter)){
print(paste("%%%%%%%%%%%%%%%%%%%%%%%%%%%% iter", iter, " %%%%%%%%%%%%%%%%%%%%%%%%%%%%"))
# dprob.iter=dprob.ALL[dprob.ALL$iter==iter,]
# #Plot change in prox vs. change in grooming
# corr.plot <- ggplot(dprob.iter,aes(dpAcc, dpSocial)) +
#   geom_point(color='blue')+
#   xlab("Change in Proximity")+ylab("Change in Grooming")+
#   ggtitle("Correlation between change in proximity and change in grooming")+
#   geom_smooth(method='lm', formula= y~x)
correl <- cor.test(dprob.iter$dpAcc,dprob.iter$dpSocial) #compute correlation
correl.coeff[iter]=correl[["estimate"]]
}
#Find mean correlation coefficient and 95% CI
mean.corr = mean(correl.coeff)
CI = quantile(correl.coeff,probs=c(0.025, 0.975))
mean.corr
CI
#Load libraries
library(ggplot2)
library(ggpubr)
library(matlab)
#Load data
load("C:/Users/Camille Testard/Documents/Github/Cayo-Maria/R.Data/ChangeP.RData")
correl.coeff=vector(); iter=1
for (iter in 1:max(dprob.ALL$iter)){
print(paste("%%%%%%%%%%%%%%%%%%%%%%%%%%%% iter", iter, " %%%%%%%%%%%%%%%%%%%%%%%%%%%%"))
dprob.iter=dprob.ALL[dprob.ALL$iter==iter,]
# #Plot change in prox vs. change in grooming
# corr.plot <- ggplot(dprob.iter,aes(dpAcc, dpSocial)) +
#   geom_point(color='blue')+
#   xlab("Change in Proximity")+ylab("Change in Grooming")+
#   ggtitle("Correlation between change in proximity and change in grooming")+
#   geom_smooth(method='lm', formula= y~x)
correl <- cor.test(dprob.iter$dpAcc,dprob.iter$dpSocial) #compute correlation
correl.coeff[iter]=correl[["estimate"]]
}
mean.corr
CI
#generate_corr.dprox.dgroom
#Are the individuals who spend more time in proximity also those that change their grooming
#freq. the most?
#Load libraries
library(ggplot2)
library(ggpubr)
library(matlab)
#Load data
load("C:/Users/Camille Testard/Documents/Github/Cayo-Maria/R.Data/ChangeP.RData")
correl.coeff=vector(); iter=1
for (iter in 1:max(dprob.ALL$iter)){
print(paste("%%%%%%%%%%%%%%%%%%%%%%%%%%%% iter", iter, " %%%%%%%%%%%%%%%%%%%%%%%%%%%%"))
dprob.iter=dprob.ALL[dprob.ALL$iter==iter,]
# #Plot change in prox vs. change in grooming
# corr.plot <- ggplot(dprob.iter,aes(dpAcc, dpSocial)) +
#   geom_point(color='blue')+
#   xlab("Change in Proximity")+ylab("Change in Grooming")+
#   ggtitle("Correlation between change in proximity and change in grooming")+
#   geom_smooth(method='lm', formula= y~x)
correl <- cor.test(dprob.iter$dpAcc,dprob.iter$dpSocial) #compute correlation
correl.coeff[iter]=correl[["estimate"]]
}
mean.corr = mean(correl.coeff)
mean(correl.coeff)
CI = quantile(correl.coeff,probs=c(0.025, 0.975))
CI
library(ggplot2)
library(lme4)# Generalized Linear Mixed Models
library(glmmTMB)
library(bbmle)#Tools for General Maximum Likelihood Estimation
library(DHARMa) #residual diagnostic fr hierarchical (multi-level/mixed) regression models
library(jtools)
library(data.table)
library(gridExtra)
library(matrixStats)
#load & format data
load("C:/Users/Camille Testard/Documents/GitHub/Cayo-Maria/R.Data/PartnerAttributes_groom.RData")
PartnerAttr$groupyear = paste(PartnerAttr$group, PartnerAttr$year, sep="")
PartnerAttr$isPost = as.factor(PartnerAttr$isPost)
for (col in seq(6,33)) {PartnerAttr[,col] = as.numeric(PartnerAttr[,col])}
#Separate data by grooming and groomimity
data.groom = PartnerAttr[which(PartnerAttr$action=="groom"),]
data.groom.V=data.groom[data.groom$group=="V",];data.groom.KK=data.groom[data.groom$group=="KK",]
#Select columns of interest
data.V.pre = data.groom.V[data.groom.V$isPost==0,8:33]; data.V.post = data.groom.V[data.groom.V$isPost==1,8:33];
data.KK.pre = data.groom.KK[data.groom.KK$isPost==0,8:33]; data.KK.post = data.groom.KK[data.groom.KK$isPost==1,8:33];
setwd('C:/Users/Camille Testard/Documents/GitHub/Cayo-Maria/R.Data')
load("Check_Indep_Obs.RData")
hist(mean_num_obs_pre)
hist(mean_num_obs_post, add=T)
hist(mean_num_obs_pre)
hist(mean_num_obs_post, add=T)
hist(mean_num_obs_pre, xlim(2,8))
hist(mean_num_obs_post, add=T)
hist(mean_num_obs_pre, xlim=c(2,8))
hist(mean_num_obs_pre, xlim=c(2,11))
hist(mean_num_obs_post, add=T)
hist(mean_num_obs_pre, xlim=c(2,12))
hist(mean_num_obs_post, add=T)
